


### Dar dos razones de por qu√© los caches son √∫tiles. ¬øQu√© problemas resuleven? ¬øQu√© problemas causan? OK

La memoria cach√© consiste en un √°rea de almacenamiento de informaci√≥n de alta velocidad. Es m√°s r√°pida que el almacenamiento primario, aunque m√°s lenta que los registros. Optimizan el acceso a memoria.

* Permiten acceder r√°pidamente a datos en uso por un programa, aprovechando el principio de localidad. La idea b√°sica es que, al momento de buscar un dato, primero se busca en la cach√©, y si se encuentra, ocurre un cache hit y el dato puede obtenerse directamente. En caso contrario, ocurre un cache miss y se busca en el almacenamiento primario un bloque que contenga el dato requerido.

* Se emplean para almacenar instrucciones. Sin esta cach√©, cada fetch de instrucci√≥n requerir√≠a leer de la memoria principal, lo que introducir√≠a una latencia de varios ciclos por cada instrucci√≥n.

Aunque tambi√©n problemas como la consistencia entre procesos-hilos de un sistema con varios n√∫cleos. Las inconsistencias pueden surgir, por ejemplo, si un hilo o proceso escribe en un √°rea de memoria compartida, y el cambio queda oculto porque el otro hilo o proceso lee una cach√© desactualizada

### ¬øQu√© es un cambio de contexto (CC)? OK

Un cambio de contexto es el proceso mediante el cual un sistema operativo detiene la ejecuci√≥n de un proceso o hilo y transfiere el control a otro.

### Describir las acciones que son tomadas por el kernel para hacer un cambio de contexto.     OK

Al haber un CC, el sistema realiza 3 acciones:

1. Guarda en el PCB la informaci√≥n relacionada al proceso que se est√° ejecutando
2. Detiene al proceso ejecut√°ndose y carga el contexto del otro proceso elegido entre los que est√°n en la tabla de procesos - seg√∫n la pol√≠tica del programa - , para as√≠ ejecutarlo
3. Al terminar la ejecuci√≥n, debido al contexto ya cargado, puede reanudar la ejecuci√≥n del proceso detenido.

### ¬øPara qu√© sirve un int√©rprete de comandos? ¬øPor qu√© usualmente est√°n separados del kernel? OK

Un int√©rprete de comandos sirve como intermediarios entre el usuario y el kernel (SO).

* Si el comando solicitado por el usuario se encuentra incluido en el int√©rprete, el kernel lo buscar√° y ejecutar√°
* Si el comando est√° en un programa externo, el kernel llamar√° a ese programa para ejecutarlo y luevo devolver√° su retorno.

Est√° usualmente separado del kernel para poder modificarlo o actualizarlo sin involucar al SO.

### ¬øQu√© es un API? OK

Una API (Application Programming Interface) es una ayuda para los programadores. Permite obtener funcionalidades ya modularizadas sin necesidad de conocer exactamente c√≥mo funcionan internamente, solamente debemos de conocer sus argumentos y el valor de retorno para poder utilizarlas. Un ejemplo, las funciones de threads provienen de la API POSIX.

Adem√°s, el uso del API mejora la portabilidad del programa entre distintos sistemas, ya que un programa que utiliza un API puede funcionar en diferentes sistemas que lo soporten, sin necesidad de modificar el c√≥digo.

Detr√°s del uso del API, el Runtime Environment (RTE) se encarga de servir como intermediario entre la aplicaci√≥n y el sistema operativo.

***



***

### ¬øQu√© es la multiprogramaci√≥n? OK

La multiprogramaci√≥n se trata de programaci√≥n en varios n√∫cleos que permiten ejecutar procesos/hilos en ellos y estas ejecuciones son al mismo tiempo. Por ello, son mayormente m√°s r√°pidas puesto que maximizan el uso de la PC y la CPU. (Mayor trabajo, en menos tiempo)

### ¬øQu√© es programaci√≥n concurrente? OK

La programaci√≥n concurrente son t√©cnicas de programaci√≥n como mutex, sem√°foros y sincronizaci√≥n permite a las tareas ejecutarse "simultaneamente", gestionandolas con hilos y procesos. En computadoras de un n√∫cleo esto se simula mediante un orden de ejecuci√≥n.

### ¬øEs posible tener concurrencia pero no paralelismo? OK

S√≠, es posible. Al igual que al rev√©s o tambi√©n que pase las 2/ninguna.

***

# P1: GENERAL.


### ¬øQu√© es el PCB (Process Control Block)? OK-

El Process Control Block (PCB), o bloque de control de procesos, es una estructura que representa cada proceso dentro del sistema operativo. Contiene informaci√≥n necesaria para iniciar o reiniciar un proceso, junto con algunos datos de contabilidad. </br>
El PCB contiene: </br>

* 1 **Estado del proceso:** indica el estado del proceso, el cual puede ser: nuevo, en ejecuci√≥n, en espera, listo, finalizado o zombie. </br>

* 2 **Contador de programa:** contiene la direcci√≥n de la pr√≥xima instrucci√≥n que debe ejecutarse para el proceso. </br>

* 3 **Registros del procesador:** contienen acumuladores, registros de √≠ndice, punteros de pila y registros de prop√≥sito general, adem√°s de cualquier c√≥digo de condici√≥n. Esta informaci√≥n se guarda cuando ocurre una interrupci√≥n para permitir que el proceso pueda continuar correctamente cuando se reprograma para ejecutarse. </br>

* 4 **Informaci√≥n de programaci√≥n:** incluye la prioridad del proceso, punteros a colas de planificaci√≥n y cualquier otro par√°metro necesario para la planificaci√≥n por parte del sistema operativo. </br>

* 5 **Informaci√≥n de gesti√≥n de memoria:** incluye los valores de registros base y l√≠mite, tablas de p√°ginas o tablas de segmentos, dependiendo del sistema de memoria utilizado por el sistema operativo. </br>

* 6 **Informaci√≥n de contabilidad:** incluye la cantidad de CPU y tiempo real utilizados, l√≠mites de tiempo, n√∫meros de cuenta y n√∫meros de trabajo o proceso. </br>

* 7 **Informaci√≥n de dispositivos de E/S:** incluye la lista de dispositivos de entrada/salida asignados al proceso, lista de archivos abiertos y otros recursos de E/S utilizados por el proceso. </br>

***

### ¬øQu√© es un m√≥dulo del kernel? OK

Un m√≥dulo del kernel (kernel module) es una parte del c√≥digo del n√∫cleo que puede ser cargada o descargada din√°micamente sin necesidad de reiniciar el sistema operativo.&#x20;

Caracter√≠sticas:

Permite agregar funcionalidades al kernel en tiempo de ejecuci√≥n (por ejemplo, nuevos drivers de dispositivos).

Se maneja con comandos como insmod, rmmod, lsmod en Linux.

Ejemplos: drivers de red, m√≥dulos de sistemas de archivos, extensiones de seguridad.

¬øPor qu√© son √∫tiles?

El kernel puede mantenerse peque√±o y modular.

Solo se cargan los m√≥dulos necesarios.

***

### ¬øEl modo usuario y modo kernel, son modos de trabajo del hardware o del sistema? Explique OK

El **modo usuario** y el **modo kernel** son modos de trabajo del sistema que se utilizan para distinguir qu√© tareas son ejecutadas por parte del usuario, y cu√°les por parte del sistema operativo. Dado que los usuarios en un sistema comparten recursos con el SO, el prop√≥sito de estos modos es proteger a otros programas, e incluso al sistema operativo en s√≠ mismo, de la ejecuci√≥n de c√≥digo que les pueda causar da√±o y/o impedir su correcto funcionamiento. Si bien a este tipo de c√≥digo se lo suele llamar "malicioso", no necesariamente se trata √∫nicamente de programas que intencionalmente intenten impedir el correcto funcionamiento de otros, sino que tambi√©n puede provenir de programas "incorrectos". Por ejemplo, un programa que acceda fuera de su espacio de memoria asignado por un error en su programaci√≥n puede provocar da√±os a otros programas en la memoria.

Para lograr esta protecci√≥n, los modos restringen qu√© instrucciones puede ejecutar el procesador dependiendo de aquel en que se encuentra el sistema en un momento dado. A aquellas instrucciones que pueden causar da√±o a otros programas si se las usa incorrectamente, se las llama **instrucciones privilegiadas**, y s√≥lo se pueden ejecutar cuando el procesador se encuentra en modo kernel.

## ¬øC√∫ales de las siguientes operaciones deben ser privilegiadas? OK

```
    a) Setear un valor del timer.
    b) Leer el clock.
    c) Limpiar la memoria.
    d) Apagar las interrupciones.
    e) Modificar la entrada de la table de estados de los dispositivos.
    f) Cambiar de modo usuario a modo kernel.
    g) Acceder a un dispositivo de entrada y salida.
```

Las operaciones que afectan al sistema completo o a otros procesos deben ser privilegiadas (solo ejecutables en modo kernel).

a) Setear un valor del timer ‚Üí ‚úÖ S√≠, privilegiada (controla interrupciones de tiempo)

b) Leer el clock ‚Üí ‚ùå No, no es privilegiada (solo lectura de datos)

c) Limpiar la memoria ‚Üí ‚úÖ S√≠, privilegiada (puede afectar otros procesos)

d) Apagar las interrupciones ‚Üí ‚úÖ S√≠, privilegiada (afecta control de CPU)

e) Modificar la entrada de la tabla de estados de los dispositivos ‚Üí ‚úÖ S√≠, privilegiada (cambia dispositivos del sistema)

f) Cambiar de modo usuario a modo kernel ‚Üí ‚ùå No directamente. El cambio a kernel se produce solo mediante un trap controlado (no puede forzarlo un programa).

g) Acceder a un dispositivo de entrada y salida ‚Üí ‚úÖ S√≠, privilegiada (los I/O devices se manejan solo desde kernel)

***

La implementaci√≥n m√°s sencilla de los modos es mediante hardware, a partir de establecer un bit en un registro del procesador que indica el modo actual, conocido como el **bit de modo** (_mode bit_, en ingl√©s). As√≠, si el sistema se encuentra en modo kernel, se lo suele representar con un `0` en el bit de modo, y si se encuentra en modo usuario, se lo representa con el bit `1`.

De esta forma, cuando arranca el sistema, √©ste se encuentra en modo kernel y se carga el sistema operativo, el cual luego inicia las aplicaciones a nivel usuario en el modo con el mismo nombre. Cuando alguna aplicaci√≥n requiere de alg√∫n recurso de parte del SO, lo hacen a trav√©s de una **llamada al sistema** (_syscall_, en ingl√©s)[^2] que ejecuta un _trap_[^1] para establecer el bit de modo en 0, o sea, en modo kernel. En este modo, el SO determina si la operaci√≥n solicitada por la aplicaci√≥n es v√°lida y "legal" (es decir, que se encuentra permitida dentro del contexto del programa que la solicit√≥), y en ese caso la ejecuta, seguido de devolverle el control, habiendo ya revertido el bit de modo a `1` (modo usuario).

Existen implementaciones m√°s complejas donde el bit de modo puede tomar m√°s de dos valores, conocidos como **anillos de protecci√≥n** (_protection rings_, en ingl√©s), que permiten distinguir entre modos adicionales, como aquellos destinados a servicios del sistema operativo, o para virtualizaci√≥n. El uso de estos anillos implementados en el procesador depende del sistema operativo, siendo a veces poco com√∫n el uso de algunos, como es el caso de los anillos 1 y 2 en procesadores Intel con 4 rings, donde los √∫nicos normalmente utilizados son el anillo 0 (modo kernel) y el 3 (modo usuario).

## Algunas CPUs proveen m√°s de 2 modos de operaci√≥n. ¬øC√∫ales son los dos usos posibles de esos m√∫ltiples modos? OK

Cuando una CPU ofrece m√°s de 2 modos (m√°s all√° de "usuario" y "kernel"), estos se usan para:

Separar niveles de privilegio en servicios del sistema operativo
Ejemplo: drivers de hardware pueden correr en un modo intermedio entre kernel y usuario.

Soportar virtualizaci√≥n segura
Ejemplo: hipervisores o m√°quinas virtuales corriendo en un "modo de virtualizaci√≥n" diferente del sistema operativo principal.

(üìç Los famosos protection rings: anillo 0 = kernel, anillo 3 = usuario; anillos 1 y 2 poco usados)

***

En el caso en el que alg√∫n programa intente ejecutar una instrucci√≥n privilegiada en modo usuario, el hardware impide su ejecuci√≥n y le informa al SO mediante un "hardware trap" (una "excepci√≥n" por hardware s√≠ncrona) para que que √©ste lo maneje. T√≠picamente, el resultado de esto es que el programa sea finalizado.

Dicho todo esto, el modo usuario y el modo kernel son, al fin y al cabo, modos conceptuales de trabajo del sistema, en particular utilizados por el SO, cuyos detalles de implementaci√≥n var√≠an seg√∫n el sistema. Casi siempre su funcionalidad se implementa por hardware (en particular, en el procesador), y permiten proteger al sistema operativo y al resto de programas, de otros programas que intenten ejecutar instrucciones que puedan impedir el correcto funcionamiento de los primeros.

[^1]: Cabe aclarar que la definici√≥n de _trap_ es ambig√ºa y puede variar seg√∫n la bibliograf√≠a o su definici√≥n en una arquitectura, pudi√©ndose referir de forma general a una interrupci√≥n, como a interrupciones por software, o incluso aquellas por software que espec√≠ficamente son s√≠ncronas. En este caso, se lo usa en el contexto de una definici√≥n com√∫n para la arquitectura x86, donde un _trap_ es una "excepci√≥n" por software, com√∫nmente utilizada para implementar llamadas al sistema.

[^2]: ## ¬øQu√© es una llamada al sistema? ¬øC√∫ales son su prop√≥sito? OK

Una llamada al sistema (system call) es el mecanismo controlado por el cual un programa en modo usuario solicita un servicio al sistema operativo (en modo kernel).

Prop√≥sito:

Permitir que los programas usen funcionalidades cr√≠ticas del sistema (leer archivos, usar red, asignar memoria, etc.)

Proteger el sistema: solo a trav√©s de system calls controladas un proceso puede acceder a recursos.



# P2: THREADS - PROCESOS

### ¬øC√∫al es la diferencia entre hilos y procesos en Linux? OK-

Las principales diferencias entre los procesos y los threads son:

* Los Hilos dentro de un mismo proceso comparten su espacio de direcciones, memoria global y otros atributos como el PID, lo cual hace que sea m√°s f√°cil compartir informaci√≥n entre estos. Basta con que copien los datos a compartir en variables compartidas (en el segmento de heap o el de data). En cambio, con los procesos se dificulta, ya que al realizar un fork, el padre y el hijo no comparten memoria. En estos casos se debe recurrir a mecanismos de memoria compartida (shm).

* La inicializaci√≥n de un nuevo Proceso mediante fork() es mucho m√°s costosa que la creaci√≥n de un nuevo Hilo, ya que hay que duplicar varios de sus atributos como sus p√°ginas de tablas y file descriptors (a√∫n utilizando la t√©cnica de copy-on-write), mientras que al crear un Hilo estos son simplemente compartidos entre ellos.

* Como los hilos comparten su memoria, un error en alguno de ellos puede propagarse al resto de los hilos sobre el mismo Proceso, en el peor de los casos terminando con el mismo. En procesos, esta situaci√≥n se evita ya que cada uno tiene su propia memoria.

* Al programar con Hilos hay que asegurarse que las funciones sean `Thread-Safe` , mediante el uso de Mutex y otros m√©todos para evitar condiciones de carrera, Deadlocks y otros.

* Los Hilos de un mismo proceso compiten por el uso de una √∫nica memoria virtual, lo cual puede causar problemas en casos con una gran cantidad de Hilos o cuando estos necesiten abundante memoria. Mientras, en cambio, los Procesos tienen la totalidad de su memoria virtual disponible.

* Todos los Hilos deben correr sobre el mismo programa, mientras que con los procesos estos pueden ser resultado de correr diferentes programas.

* Realizar un cambio de contexto entre hilos suele ser m√°s r√°pido que un cambio entre procesos, ya que los hilos comparten gran parte de su entorno. En particular, como comparten memoria al realizar un CC no se requiere un intercambio de p√°ginas virtuales, una de las operaciones m√°s costosas.

***

### ¬øC√∫al es la diferencia entre threads de nivel de usuario y de nivel kernel? ¬øEn c√∫ales circuntancias uno es mejor que otro? OK

#### THREADS DE NIVEL USUARIO:

* Gesti√≥n: Son gestionados por bibliotecas de threading en el espacio de usuario, sin interacci√≥n directa con el kernel.

* Cambio de contexto: Los cambios entre threads de nivel de usuario son m√°s r√°pidos, ya que no requieren intervenci√≥n del kernel.

Ventajas:

* M√°s eficientes y veloces en sistemas con una sola CPU.

* Ideales cuando la aplicaci√≥n no requiere utilizar varias CPUs o cuando la interacci√≥n con el kernel es limitada.

Desventajas:

* Si un thread realiza una llamada bloqueante al sistema, todos los threads de ese proceso se quedan bloqueados, ya que el kernel no tiene conocimiento de los threads individuales.

* No aprovechan m√∫ltiples n√∫cleos de la CPU, dado que el kernel considera el proceso como un √∫nico hilo.

#### Threads de nivel kernel

* Gesti√≥n: Son gestionados directamente por el kernel del sistema operativo.

* Cambio de contexto: Los cambios entre threads de nivel kernel son m√°s costosos, ya que requieren intervenci√≥n del kernel.

Ventajas:

* Pueden aprovechar m√∫ltiples CPUs en sistemas con soporte para multiprocesamiento.

* Si un thread se bloquea, otros threads del mismo proceso pueden seguir ejecut√°ndose.

Desventajas:

* Son menos eficientes en sistemas con una sola CPU debido al mayor costo de manejo por parte del kernel.

#### Circunstancias ideales para cada uno:

Threads de nivel de usuario:

* Aplicaciones que no requieren aprovechar m√∫ltiples n√∫cleos de CPU.

* Sistemas donde el rendimiento es cr√≠tico y las llamadas al sistema son m√≠nimas.

* Entornos con recursos limitados, donde reducir la carga del kernel es importante.

Threads de nivel kernel:

* Aplicaciones intensivas que necesitan ejecutar en paralelo en m√∫ltiples n√∫cleos.

* Programas que realizan muchas llamadas al sistema o interact√∫an extensamente con el hardware.

* Escenarios donde la robustez y la capacidad de manejar bloqueos son prioritarios.

### ¬øQu√© recursos son usados cuando se crean threads? ¬øC√≥mo difiere de los recursos usados cuando se crea un proceso? OK

Los recursos que son usados cuando se crean threads son:

1- Espacio de direcciones : Comparte el mismo espacio de direcciones (memoria) que su proceso padre y los dem√°s threads.

2- Segmento de texto, heap, datos globales y archivos abiertos(files descriptors): Compartido por todos los threads.

3- Stack: Es individual de cada thread.

4- Registros y contador de programa: Individuales de cada thread.

Cuando se crea un proceso esos recursos son usados de la siguiente forma:

1- Espacio de direcciones : Cada proceso tiene su propia memoria.

2- Segmento de texto, heap, datos globales y archivos abiertos(files descriptors):
Cada proceso hace una copia.

3- Stack: Es individual de cada proceso.

4- Registros y contador de programa: Individuales de proceso

*Es decir, espacio de direcciones y heap+fd: hilos:compartido, proceso:individual*

*Stack, registros y contador de programa: individual en ambos.*

### Describir el mecanismo por el c√∫al se refuerza la protecci√≥n para prevenir que un programa modifique la memoria asociada a otro programa OK-

El mecanismo que refuerza la protecci√≥n para evitar que un programa modifique la memoria de otro programa se basa en la colaboraci√≥n entre el sistema operativo y el hardware, utilizando los siguientes elementos:

* **Registros base y l√≠mite**: Cada proceso cuenta con un registro base que se√±ala el inicio de su √°rea de memoria permitida y un registro l√≠mite que define el tama√±o autorizado. El hardware verifica autom√°ticamente que todas las direcciones de memoria accedidas se encuentren dentro del rango entre el registro base y el l√≠mite.

* **Memoria paginada o segmentada**: La Unidad de Gesti√≥n de Memoria (MMU, por sus siglas en ingl√©s) traduce las direcciones virtuales a direcciones f√≠sicas, permitiendo que cada proceso perciba su propia memoria virtual, completamente aislada de otros.

* **Permisos de p√°gina**: Cada p√°gina de memoria tiene asignados permisos espec√≠ficos (lectura, escritura, ejecuci√≥n). Si un proceso intenta un acceso indebido, el hardware genera una excepci√≥n que permite al sistema operativo finalizar el proceso infractor.

En conjunto, estos mecanismos garantizan que la memoria de cada proceso est√© protegida frente a accesos no autorizados, evitando da√±os o lectura indebida por parte de otros procesos.

***

### ¬øQu√© es exclusi√≥n mutua? OK

La exclusi√≥n mutua (MUTEX) es un mecanismo que permite manejar los errores como race condition y deadlock a trav√©s de asegurar que los hilos sean THREAD-SAFE. Busca garantizar que dos o m√°s procesos no puedan acceder dentro de su regi√≥n cr√≠tica al mismo tiempo.

### ¬øQu√© mecanismos para lograr exclusi√≥n mutua podemos usar? OK

Si bien hay muchos m√©todos que se pueden usar para exclusi√≥n mutua vamos a ver los que se cubrieron en la materia:

#### Deshabilitar interrupciones

Una primera opci√≥n basada en hardware, se basa en que cada proceso deshabilite las interrupciones antes de entrar a la zona cr√≠tica y las vuelva a habilitar al salir; Eso funciona porque el CPU solo cambia de un proceso a otro cuando ocurre una interrupci√≥n.
Si bien este m√©todo funciona, no es bueno, pues es mala idea darle control a procesos con nivel de usuario la posibilidad de deshabilitar las interrupciones, junto con esto en un sistema con m√∫ltiples n√∫cleos hacer esto solo afecta al n√∫cleo que ejecut√≥ la instrucci√≥n, los otros contin√∫an funcionando normalmente.

#### Variables de lock

Como segunda posibilidad podemos pensar en exclusi√≥n basada en software, en particular en usar una bandera. Esta se almacena en una variable compartida, accesible a todos los threads, con un valor inicial de 0. Cuando un proceso quiere ingresar a la zona cr√≠tica revisa si la bandera es 0; Si lo es le cambia el valor a 1 e ingresa a la zona cr√≠tica, de lo contrario espera a que se vuelva 0.
El problema que tiene este m√©todo es que la comparaci√≥n y asignaci√≥n no es una operaci√≥n at√≥mica. Es decir puede ocurrir que un proceso lea el valor de la bandera y vea que es 0; Justo despu√©s ocurre un cambio de contexto y un segundo proceso lee el valor de la bandera, que sigue siendo 0, pues no fue actualizado. Como consecuencia de esto los dos procesos entran a la zona cr√≠tica.

<table>
<tr>
<th>C</th>
<th>x86-assembly</th>
</tr>
<tr>
<td>

```C
while (bandera);
bandera= 1;
/*
    Zona critica       
*/         
bandera= 0;
```

</td>
<td>

```C
LOOP:
    movl    FLAG(%rip), %eax
    testl   %eax, %eax
    jne     LOOP
    movl    $1, FLAG(%rip)
    movl    $0, FLAG(%rip)
```

</td>
</tr>
</table>
En el ejemplo de arriba vemos c√≥mo revisar el valor de la bandera y poner su valor en 1 se traduce a 4 instrucciones de x86, lo que causa que la operaci√≥n no sea at√≥mica.

#### CAS

Una forma de implementar exclusi√≥n con una variable de lock, que funcione correctamente, es usando **CAS**(Compare and swap). Esta es una instrucci√≥n at√≥mica provista por varias arquitecturas, tiene la forma `CAS(l,a,b)`; Lo que hace es leer el valor en la direcci√≥n de memoria `l`, si es igual a `a` se almacena `b` en la direcci√≥n a la que apunta `l`, de lo contrario no hace nada. Al mismo tiempo devuelve un booleano indicando si ocurre el cambio o no. En el caso de x86-64 **CAS** se puede implementar usando la instrucci√≥n `cmpxchg`.
Esto nos permite usar una variable de lock, ya que podemos hacer la comparaci√≥n y la asignaci√≥n a la bandera de forma at√≥mica, lo que resuelve el problema del punto anterior. Presentamos una implementaci√≥n de este metodo de exclusion usando C y `cmpxchg`:

<table>
<tr>
<th>Definici√≥n de CAS </th>
<th>Uso de CAS</th>
</tr>
<tr>
<td>

```C
int CAS(volatile int *ptr, int expected, int new_val) {
    unsigned char success;
    
    __asm__ volatile (
        "lock cmpxchg %2, %1\n\t"
        "sete %0"
        : "=q" (success),
          "+m" (*ptr),
          "+r" (new_val)
        : "a" (expected)
        : "memory"
    );

    return success;
}
```

</td>
<td>

```C
//La bandera debe ser una variable global
int flag = 0;

void *funcionThread(void* arg) {
    //Lock de zona cr√≠tica. Al ingresar causa flag = 1.
    while(!CAS(&flag, 0, 1));

    /*
        Zona critica
    */

    flag = 0;

    return NULL;
}
```

</td>
</tr>
</table>

#### Alternancia estricta

Otro m√©todo posible de exclusi√≥n basado en software se basa en usar una variable de turno, esta indica cu√°l de los procesos puede acceder a la zona cr√≠tica. En forma general un proceso entra a la zona cr√≠tica cuando el n√∫mero de la variable de turno es igual a su n√∫mero de proceso, al salir de la zona cr√≠tica este incrementa la variable de turno en 1, permitiendo que otro proceso acceda a la zona cr√≠tica. Para mayor claridad vemos un ejemplo con solo dos procesos:

<table>
<tr>
<th>Codigo del proceso 0</th>
<th>Codigo del proceso 1</th>
</tr>
<tr>
<td>

```C
while (1) {
    while (turno != 0);
    /*
        Region critica
    */
    turno = 1;
}
```

</td>
<td>

```C
while (1) {
    while (turno != 1);
    /*
        Region critica
    */
    turno = 0;
}
```

</td>
</tr>
</table>

Si bien este m√©todo evita accesos simult√°neos a la zona critica requiere que todos los procesos utiliz√°ndolo se alternan de forma estricta, es decir:  $P_{1}  \implies  P_{2}   \implies P_{3}   \implies  ...  \implies  P_{1}$. De lo contrario un proceso ceder√° su turno pero no habr√° quien se lo d√© nuevamente; Usando el c√≥digo anterior como ejemplo, digamos que el proceso 0 termina, cuando el proceso 1 sale de la regi√≥n cr√≠tica le cede su turno al proceso 0. Sin embargo como el proceso 0 ya no se est√° ejecutando nunca le devuelve el turno, causando que el proceso 1 se quede esperando, violando la propiedad de *liveness*.

#### Algoritmo de Peterson

Este algoritmo es una mejora de el propuesto por T. Dekker (Matem√°tico de los Pa√≠ses Bajos), siendo significativamente m√°s simple. Se basa en una variable de turno y una lista que indica la intenci√≥n de ejecutarse de un proceso. Veremos la versi√≥n para dos procesos, sin embargo es posible modificar el algoritmo para trabajar con `n` procesos, introduciendo `n` niveles de espera. En la pr√°ctica antes de ingresar a la zona cr√≠tica cada proceso indica su intenci√≥n de ejecutarse, poniendo en `true` su posici√≥n en la lista de inter√©s, luego le pasa el turno al otro proceso. Habiendo hecho esto espera a que el proceso al que le pas√≥ el turno salga de la zona cr√≠tica, momento en el que le pasa el turno, permiti√©ndole al proceso entrar en la zona cr√≠tica. A continuaci√≥n se da una implementaci√≥n de este algoritmo en C:

<table>
<tr>
<th>Codigo del proceso 1</th>
<th>Codigo del proceso 2</th>
</tr>
<tr>
<td>

```C
//Lock
flag[0] = 1; //El proceso 1 quiere el turno.
turn = 2; //Le pasa el turno al proceso 2.
while (flag[1] == 1 && turn == 2);

/*
    Zona critica
*/

//El proceso 1 ya no quiere el turno.
flag[0] = 0;
```

</td>
<td>

```C
//Lock
flag[1] = 1; //El proceso 2 quiere el turno.
turn = 1; //Le pasa el turno al proceso 1.
while (flag[1] == 1 && turn == 2);

/*
    Zona critica
*/

//El proceso 2 ya no quiere el turno.
flag[1] = 0;
```

</td>
</tr>
</table>

#### Algoritmo de Lamport

Este algoritmo fue inventado por L. Lamport, la idea es simular el sistema de tickets de una panader√≠a, usando una analog√≠a: Un cliente(Proceso) toma un n√∫mero y se pone en la fila, esperando que sea su turno de que lo atiendan(Ejecutarse), donde el panadero(El algoritmo) va atendiendo y llamando los n√∫meros.

En la pr√°ctica este algoritmo usa dos listas, una que indica el "n√∫mero de ticket" de cada proceso y otra que los procesos usan para indicar si est√°n eligiendo un ‚Äún√∫mero de ticket‚Äù. Cuando un proceso quiere ingresar a la secci√≥n cr√≠tica, primero se le asigna su n√∫mero de ticket, el m√°s alto de todos los procesos. C√≥mo calcular el n√∫mero de ticket no es una operaci√≥n at√≥mica, el proceso indica que est√° eligiendo usando la lista de elecci√≥n. Esto es para prevenir que otro proceso revise el n√∫mero de ticket que a√∫n no se termin√≥ de calcular. Finalmente el proceso verifica que su n√∫mero de ticket sea el menor, si es as√≠ entonces "es su turno", puede entrar a la zona cr√≠tica, de lo contrario espera hasta tener el menor n√∫mero de ticket. Al salir de la zona cr√≠tica el n√∫mero de ticket del proceso se vuelve cero, indicando que no tiene inter√©s en acceder a la misma.

Presentamos una implementaci√≥n del algoritmo en C, donde `NUM` y `CHOOSING` son variables globales:

```C
void lock(const int index) {
    //El proceso indica que est√° obteniendo un n√∫mero.
    CHOOSING[index] = true;
    //El proceso obtiene su n√∫mero.
    int max = NUM[0];
    for (int i = 1; i < N; i++)
        if (NUM[i] > max)
            max = NUM[i];
    NUM[index] = max + 1;
    //El proceso obtuvo un n√∫mero.
    CHOOSING[index] = false;

    for (int j = 0; j < N; j++)
    {
        //El proceso espera a que nadie est√© eligiendo un n√∫mero.
        while (CHOOSING[j]);

        //El proceso espera a tener el menor n√∫mero.
        while ((NUM[j] != 0) && ((NUM[j] < NUM[index]) || ((NUM[j] == NUM[index]) && (j < index))));
    }
}

void unlock(const int index) {
    NUM[index] = 0;
}
```

#### Mutexes

Todos los m√©todos de exclusi√≥n mutua que explicamos hasta ahora comparten una caracter√≠stica importante, que los hace poco eficientes, el uso de *busy waiting*. As√≠ se llama cuando un proceso se queda esperando sin ceder el uso del procesador, es decir el proceso se sigue ejecutando verificando constantemente si se cumple una condici√≥n; En los m√©todos vistos esto se hac√≠a con un loop . Si bien hacer esto funciona es muy ineficiente, pues se desperdicia mucho tiempo de ejecuci√≥n.

La soluci√≥n que vimos en clase es utilizar un *mutex*; Un *mutex* es una variable compartida que tiene dos estados, bloqueada o desbloqueada. Cuando un proceso quiere ingresar a la zona cr√≠tica est√© consulta el estado del *mutex*, si est√° desbloqueado lo bloquea e ingresa a la zona cr√≠tica, de lo contrario el proceso deja de ejecutarse, liberando el CPU. La pr√≥xima vez que el proceso se ejecute volver√° a revisar el estado del *mutex*.
En C el uso de mutexes requiere la librer√≠a *pthread.h*, adem√°s se debe compilar usando las flags `-pthread` y `-lrt`, en ese orden. Esta librer√≠a incluye las funciones `pthread_mutex_lock(mutex)` y `pthread_mutex_unlock(mutex)` que bloquean y desbloquean el mutex dado; Para usarlas se requiere de una variable compartida de tipo `pthread_mutex_t`, que almacena el *mutex*. Se presenta un ejemplo de uso en C:

```C
//Variable global con el mutex, hay que inicializarla.
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;

void *funcionThread(void* arg) {
    pthread_mutex_lock(&mutex);
    /*
        Zona critica
    */
    pthread_mutex_unlock(&mutex);

    return NULL;
}
```

Cuando definimos el problema Mutex lo definimos en base a una propiedad que tiene
que ser garantizada: la regi√≥n cr√≠tica es accedida por lo sumo un proceso.
Las propiedades de ‚ÄòSafety‚Äô son las que garantizan que nada malo puede pasar.
Esto lo lograremos insertando mecanismos de sincronizaci√≥n antes y despu√©s de la
secci√≥n cr√≠tica.

***

### ¬øCu√°les son los mecanismos de comunicaci√≥n entre procesos? OK

Cuando un proceso es cooperativo, necesita un mecanismo de comunicaci√≥n entre procesos (IPC). Existen dos modelos fundamentales:

* **Memoria compartida (shared memory):** En este modelo, se establece una regi√≥n de memoria com√∫n. Los procesos pueden intercambiar informaci√≥n escribiendo y leyendo en esta regi√≥n compartida. Normalmente, el sistema operativo impide que los procesos accedan a la memoria de otros, pero si dos o m√°s procesos acuerdan eliminar esta restricci√≥n, se crea una regi√≥n compartida. Es importante destacar que este m√©todo no est√° supervisado por el sistema operativo, por lo que los procesos deben gestionar la concurrencia y evitar escribir simult√°neamente en el mismo lugar.

* **Paso de mensajes (message passing):** Este modelo utiliza el env√≠o y recepci√≥n de mensajes entre procesos cooperativos. A diferencia del modelo de memoria compartida, no requiere un espacio de memoria com√∫n y permite que los procesos se comuniquen y sincronicen sus acciones, incluso entre computadoras conectadas a una red. Las funciones b√°sicas que proporciona este modelo son:
  ```C
  send(message)
  receive(message)
  ```
  Los mensajes pueden ser de tama√±o fijo o variable, cada uno con sus propias complejidades. Para establecer comunicaci√≥n entre dos procesos (por ejemplo, P y Q), es necesario crear un enlace de comunicaci√≥n (**communication link**) que puede implementarse de diversas maneras:
  * Comunicaci√≥n directa o indirecta
  * Comunicaci√≥n s√≠ncrona o as√≠ncrona
  * Buffer autom√°tico o espec√≠fico

**Tipos de comunicaci√≥n:**

1. **Comunicaci√≥n directa:** Los procesos involucrados conocen expl√≠citamente los nombres del otro, lo que implica simetr√≠a. Existe una variante asim√©trica donde un proceso env√≠a mensajes a un proceso espec√≠fico mientras otros escuchan sin especificar a qui√©n. La principal desventaja de este enfoque es la dependencia de nombres codificados (hard-coding).

2. **Comunicaci√≥n indirecta:** Los mensajes se env√≠an y reciben mediante puertos o "mailbox", identificados de forma √∫nica. Dos procesos solo pueden comunicarse si comparten un puerto. Esto puede generar problemas de concurrencia cuando varios procesos intentan acceder al mismo puerto. Los puertos pueden ser creados tanto por los procesos como por el sistema operativo, y cuando un proceso propietario de un puerto finaliza, el puerto tambi√©n desaparece, notificando a los usuarios del mismo.

**Sincronizaci√≥n:**

* Las funciones `send()` y `receive()` pueden ser bloqueantes o no bloqueantes (s√≠ncronas o as√≠ncronas). Si son bloqueantes, el proceso queda en espera hasta completar la operaci√≥n, lo cual puede resolver problemas como el del productor-consumidor, pero tambi√©n presenta inconvenientes en situaciones donde bloquear procesos no es viable.

**Buffering:**

La comunicaci√≥n entre procesos, tanto directa como indirecta, puede manejarse mediante colas que pueden implementarse de tres formas:

* **Capacidad cero:** No se permite almacenar mensajes en espera. El emisor queda bloqueado hasta que el receptor tome el mensaje.
* **Capacidad limitada:** La cola tiene un tama√±o finito (n). Si no est√° llena, los mensajes se encolan; en caso contrario, el emisor se bloquea.
* **Capacidad ilimitada:** Permite almacenar una cantidad infinita de mensajes, y el emisor nunca se bloquea.

Ambos modelos son comunes en los sistemas operativos y suelen estar implementados simult√°neamente debido a sus diferentes ventajas. Por ejemplo:

* La comunicaci√≥n a trav√©s de mensajes es ideal para transferir peque√±as cantidades de informaci√≥n, ya que implica menos complejidades.
* La memoria compartida suele ser m√°s r√°pida, ya que los mensajes se env√≠an y leen mediante llamadas al sistema, mientras que en la memoria compartida, una vez establecida la regi√≥n com√∫n, los procesos acceden directamente sin intervenci√≥n del kernel.

***

# P3: ERRORES Y +

### ¬øQu√© es en programaci√≥n concurrente regi√≥n cr√≠tica? OK

La regi√≥n cr√≠tica es un √°rea en donde los procesos intentan acceder o modificar al mismo recurso, y seg√∫n el orden de ejecuci√≥n esto puede ocasionar distintos resultados y es por ello que resulta importante protegerla (Riesgo de RACE CONDITION). La finalidad es que s√≥lo un proceso pueda ejecutarla al mismo tiempo.

## ¬øQu√© es race condition? OK

Race Condition es una categor√≠a de errores de programaci√≥n en la cual varios procesos acceden a y manipulan los mismos datos de manera concurrente. El error surge de la propia ejecuci√≥n, ya que como los procesos compiten por acceder y modificar los recursos compartidos, se pueden dar diferentes resultados que dependen del orden de dichos accesos

### ¬øQu√© es un deadlock? OK

Un **DEADLOCK** es una situaci√≥n que puede ocurrir en entornos de programaci√≥n m√∫ltiple, donde varios hilos (threads) compiten por un n√∫mero limitado de recursos. Si un hilo solicita un recurso que est√° siendo usado por otro hilo, o que no est√° disponible en ese momento, el hilo entra en un estado de espera. Este estado se denomina **DEADLOCK**, y ocurre al tener varios hilos esperando indefinidamente ya que √©stos no pueden cambiar de estado al tener el recurso pedido, que est√° tomado por otro hilo en espera. Es decir, ninguno puede continuar su ejecuci√≥n.

Para que se produzca un deadlock, se deben cumplir simult√°neamente las siguientes condiciones **necesarias**:

* ${\color{lightblue}Exclusi√≥n \space mutua}$, los recursos solo pueden ser utilizados un hilo a la vez.
* ${\color{lightblue}Hold-and-Wait \space (Retenci√≥n \space y \space espera)}$, un hilo que retiene recursos puede solicitar otros adicionales.
* ${\color{lightblue}No \space Preemption \space (No \space expropiaci√≥n)}$, los recursos deben ser liberados voluntariamente.
* ${\color{lightblue}Circular \space wait \space (Espera \space circular)}$, cadena de hilos en donde cada uno espera un recurso que posee el siguiente.

${\color{red} IMPORTANTE: \space Estas \space condiciones \space son \space necesarias, \space NO \space suficiente s\space por \space s√≠ \space solas \space para \space que \space se \space genere \space un \space deadlock.}$ </br>
Para asegurarse que nunca ocurra un deadlock, el sistema puede usar una **prevenci√≥n contra deadlock** o un **esquema de evasi√≥n de deadlock**. El primero provee una serie de m√©todos que aseguran que al menos una condici√≥n necesaria no se cumpla. El segundo necesita que se le d√© al sistema operativo informaci√≥n adicional por adelantado acerca de que recursos solicitar√° y usar√° el hilo mientras funcione.

De todas las condiciones necesarias, la de *Circular wait* es la m√°s pr√°ctica para evitar, se suele imponer un orden fijo para la solicitud de recursos, para romper el ciclo de espera.

### ¬øQu√© es un livelock? OK

*Propiedad Liveness*

* Ausencia de Deadlock
* Ausencia de Inanici√≥n: Siempre que un proceso quiera tomar un lock, eventualmente lo har√°.

*Ausencia de Inanici√≥n implica Ausencia de Deadlock, pero no funciona al rev√©s.*

Un **livelock** es otra forma de ausencia de liveness, en donde al igual que el deadlock un proceso queda en espera pero este sigue tratando se ejecutarse fallidamente en bucle.&#x20;

**C√≥mo prevenir:** Usar mecanismos de tiempo de espera o prioridad din√°mica para garantizar que los procesos eventualmente progresen

***

# P4 : M√ÅS INFO (+)

### Sincronizaci√≥n de Procesos

La sincronizaci√≥n se produce cuando uno o m√°s procesos dependen del comportamiento de otro proceso, y puede darse de dos formas:

‚óè Competencia: procesos compiten por un recurso (Ej: Acceso a una Impresora)

‚óè Cooperaci√≥n : procesos cooperan por un objetivo com√∫n. Barreras, Productor/Consumidor, etc.

En general sincronizaci√≥n es el conjunto de reglas y mecanismos que permiten la especificaci√≥n e implementaci√≥n de propiedades secuenciales de cada proceso que garantizan la correcta ejecuci√≥n de un programa concurrente.

### Operaci√≥n At√≥mica OK

Manipulaci√≥n de datos que requiere la garant√≠a de que se ejecute como una sola unidad de ejecuci√≥n, o fallar√° completamente, sin
resultados o estados parciales observables por otro proceso o en el entorno.

### Consistencia Secuencial

Asumimos

1. que las operaciones de cada procesador se realizan en el orden especificado
2. que los stores (escrituras a memoria) son inmediatamente visibles al otro procesador.

### Fence (barrera de memoria)

Un Fence (instrucci√≥n mfence) causa que la CPU:

1. No reordene instrucciones a trav√©s del mismo
2. Garantice que todas las escrituras previas al fence son visibles
   a todos los procesadores antes de continuar

***

### Spooling

El uso m√°s com√∫n del spooling es la impresi√≥n: los documentos formateados para impresi√≥n se almacenan en una cola a la velocidad de la computadora, y luego se recuperan e imprimen a la velocidad de la impresora.
M√∫ltiples procesos pueden escribir documentos en el spool sin espera y realizar otras tareas, mientras el proceso de "spooler" opera la impresora.

***

Usa shm\_open si necesitas crear un segmento de memoria compartida para que varios procesos trabajen con √©l y  mmap si quieres mapear un archivo o descriptor de memoria al espacio de direcciones de un proceso
